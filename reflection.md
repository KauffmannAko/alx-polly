# Reflection on AI in the Build Process

Throughout the development of **ALX Polly 2.0**, I relied on AI as both a coding assistant and a planning partner. This reflection captures what worked well, where I felt limited, and what I learned about prompting, reviewing, and iterating with AI tools.

---

## What Worked Well

One of the strongest contributions of AI was in **structuring the project before writing code**. By drafting prompts for project scope, tech stack, and feature breakdowns, I was able to move from a vague idea to a clear roadmap quickly. The AI helped transform raw thoughts into polished project descriptions, user stories, and even acceptance criteria. This saved time and reduced ambiguity.

During implementation, AI proved helpful in **boilerplate generation and refactoring suggestions**. Tasks such as setting up role-based access control, adding responsiveness, and ensuring accessibility were supported with code snippets and best practice recommendations. Instead of searching through scattered documentation, I could get targeted examples aligned to my context.

AI also helped with **documentation and clarity**. From drafting a `README.md` to preparing task prompts, the assistant made it easier to maintain consistent language and a professional tone. This freed me to focus more on core logic and decision-making.

---

## What Felt Limiting

Despite its strengths, AI was not flawless. The biggest limitation came from **context management**. Complex projects often involve multiple moving parts—authentication, database schema, UI components—and the AI sometimes lost track of prior constraints. This meant I had to restate context often or carefully structure prompts to avoid drift.

Another challenge was that AI could be **overconfident with outdated or incomplete information**. For example, when integrating certain libraries or tools, I still had to verify against the latest documentation. AI sometimes provided APIs or methods that were deprecated. This reinforced the need to treat its output as a draft, not a final authority.

AI also had limited ability to **make trade-off decisions**. For example, whether to allow anonymous voting or enforce strict role checks involved product-level reasoning that AI could not resolve alone. I had to step in as the decision-maker.

---

## What I Learned

The biggest lesson was that **prompting is a skill**. The quality of the output depended heavily on how I structured my requests. Clear goals, specific deliverables, and context-rich prompts produced better results. Vague or rushed prompts often led to generic or misaligned answers.

I also learned the importance of **review and iteration**. Rarely was the first AI response the final version. Instead, it worked best as a draft that I refined. By iterating—asking for corrections, improvements, or alternative phrasings—I could progressively shape the output into something useful.

Finally, I realized that AI works best as a **collaborative partner rather than a replacement for expertise**. It accelerated the build process, reduced boilerplate, and improved documentation, but the responsibility for correctness, security, and product vision always remained with me.

---

## Conclusion

AI significantly impacted the build process by improving speed, clarity, and consistency. It turned abstract goals into actionable steps and supported coding, testing, and documenting. At the same time, its limitations required me to stay critical, verify outputs, and iterate carefully. The experience taught me how to **prompt with precision, review with skepticism, and iterate with intention**—skills that will carry forward into future AI-assisted projects.
